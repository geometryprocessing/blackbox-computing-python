{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning with CAD Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Download the ABC dataset from https://deep-geometry.github.io/abc-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import meshplot as mp \n",
    "import numpy as np\n",
    "import igl\n",
    "import yaml\n",
    "from yaml import CLoader as Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Reading CAD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def read_model(obj_path, feat_path):\n",
    "    v, _, n, f, _, ni = igl.read_obj(obj_path)\n",
    "            \n",
    "    with open(feat_path) as fi:\n",
    "        feat = yaml.load(fi, Loader=Loader)\n",
    "    m = {\"vertices\": v, \"face_indices\": f, \"normals\": n, \n",
    "        \"normal_indices\": ni, \"features\": feat}\n",
    "    return m\n",
    "\n",
    "m = read_model(\"data/test_trimesh.obj\", \"data/test_features.yml\")\n",
    "v, f, feat = m[\"vertices\"], m[\"face_indices\"], m[\"features\"]\n",
    "print(v.shape, f.shape)\n",
    "print(list(feat.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CAD Features: Surface Normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from data.utils import get_averaged_normals\n",
    "\n",
    "# Average normals at vertices with multiple normals\n",
    "av_normals = get_averaged_normals(m)\n",
    "\n",
    "p = mp.plot(v, f, c=np.abs(av_normals))\n",
    "\n",
    "# Add normals to the plot\n",
    "p.add_lines(m[\"vertices\"], m[\"vertices\"] + av_normals,\n",
    "            shading={\"line_color\": \"black\"})\n",
    "\n",
    "# Determine normals with uniform weighting in libigl\n",
    "#normals = igl.per_vertex_normals(v, f)\n",
    "#p.add_lines(m[\"vertices\"], m[\"vertices\"] + normals,\n",
    "#            shading={\"line_color\": \"red\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CAD Features: Sharp Edges/Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve the sharp features\n",
    "lines = []\n",
    "for i, fe in enumerate(feat[\"curves\"]):\n",
    "    if fe[\"sharp\"]:\n",
    "        for j in range(len(fe[\"vert_indices\"])-1):\n",
    "            lines.append([fe[\"vert_indices\"][j], fe[\"vert_indices\"][j+1]])\n",
    "# Visualize the sharp features            \n",
    "p = mp.plot(v, f)\n",
    "p.add_edges(v, np.array(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CAD Features: Sharp Edges/Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve the sharp features\n",
    "v_class = np.zeros((v.shape[0], 1))\n",
    "for i, fe in enumerate(feat[\"curves\"]):\n",
    "    if fe[\"sharp\"]:\n",
    "        v_class[fe[\"vert_indices\"]] = 1\n",
    "        \n",
    "# Visualize the sharp features            \n",
    "mp.plot(v, c=-v_class, shading={\"point_size\": 4.})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CAD Features: Surface Patch Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve the surface patch types\n",
    "t_map = {\"Plane\": 0, \"Cylinder\": 1,\n",
    "         \"Cone\": 2, \"Sphere\": 3,\n",
    "         \"Torus\": 4, \"Bezier\": 5,\n",
    "         \"BSpline\": 6, \"Revolution\": 7,\n",
    "         \"Extrusion\": 8, \"Other\": 9}\n",
    "\n",
    "c1 = np.zeros(f.shape[0])\n",
    "for fe in feat[\"surfaces\"]:\n",
    "    t = t_map[fe[\"type\"]]\n",
    "    for j in fe[\"face_indices\"]:\n",
    "        c1[j] = t\n",
    "\n",
    "# Visualize the patch types\n",
    "mp.plot(v, f, -c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CAD Features: Surface Patch Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve the surface patch types per vertex\n",
    "c2 = np.zeros(v.shape[0])\n",
    "for fe in feat[\"surfaces\"]:\n",
    "    t = t_map[fe[\"type\"]]\n",
    "    for j in fe[\"vert_indices\"]:\n",
    "        c2[j] = t\n",
    "\n",
    "# Visualize the vertices\n",
    "mp.plot(v, c=-c2, shading={\"point_size\": 4.})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Machine Learning Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Installation\n",
    "\n",
    "We use [Pytorch](https://pytorch.org/) and [Pytorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/) that can be installed as described in their documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import meshplot as mp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Dropout, Linear\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import DynamicEdgeConv\n",
    "\n",
    "from data.utils import MLP\n",
    "from data.utils import ABCDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading the CAD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "tf_train = T.Compose([\n",
    "    T.FixedPoints(5000, replace=False),\n",
    "    T.RandomTranslate(0.002),\n",
    "    T.RandomRotate(15, axis=0),\n",
    "    T.RandomRotate(15, axis=1),\n",
    "    T.RandomRotate(15, axis=2)\n",
    "])\n",
    "tf_test = T.Compose([T.FixedPoints(10000, replace=False)])\n",
    "pre = T.NormalizeScale()\n",
    "\n",
    "train_dataset_n = ABCDataset(\"data/ml/ABC\", \"Normals\", True, tf_train, pre)\n",
    "test_dataset_n = ABCDataset(\"data/ml/ABC\", \"Normals\", False, tf_test, pre)\n",
    "train_dataset_e = ABCDataset(\"data/ml/ABC\", \"Edges\", True, tf_train, pre)\n",
    "test_dataset_e = ABCDataset(\"data/ml/ABC\", \"Edges\", False, tf_test, pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistics and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dataset = test_dataset_e\n",
    "print(\"Number of models:\", len(dataset))\n",
    "print(\"Number of classes:\", dataset.num_classes)\n",
    "\n",
    "counts = [0]*dataset.num_classes\n",
    "total = 0\n",
    "for d in dataset:\n",
    "    y = d.y.numpy()\n",
    "    for i in range(dataset.num_classes):\n",
    "        counts[i] += np.sum(y==i)\n",
    "    total += y.shape[0]\n",
    "\n",
    "for i, c in enumerate(counts):\n",
    "    print(\"%0.2f%% labels are of class %i.\"%(c/total, i))\n",
    "    \n",
    "d = test_dataset_e[3]\n",
    "v = d.pos.numpy()\n",
    "y = d.y.numpy()\n",
    "print(\"Shape of model:\", v.shape)\n",
    "print(\"Shape of labels:\", y.shape)\n",
    "\n",
    "mp.plot(v, c=-y, shading={\"point_size\": 0.15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = test_dataset_n[4]\n",
    "v = d.pos.numpy()\n",
    "y = d.y.numpy()\n",
    "mp.plot(v, c=np.abs(y), shading={\"point_size\": 0.15})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Defining the Network (DGCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, out_channels, k=30, aggr='max', \n",
    "                 typ='Edges'):\n",
    "        super(Net, self).__init__()\n",
    "        self.typ = typ\n",
    "        self.conv1 = DynamicEdgeConv(MLP([2 * 3, 64, 64]), k, aggr)\n",
    "        self.conv2 = DynamicEdgeConv(MLP([2* 64, 64, 64]), k, aggr)\n",
    "        self.conv3 = DynamicEdgeConv(MLP([2* 64, 64, 64]), k, aggr)\n",
    "        self.lin1 = MLP([3 * 64, 1024])\n",
    "\n",
    "        self.mlp = Sequential(MLP([1024, 256]), Dropout(0.5), \n",
    "                              MLP([256, 128]), Dropout(0.5), \n",
    "                              Linear(128, out_channels))\n",
    "\n",
    "    def forward(self, data):\n",
    "        pos, batch = data.pos, data.batch\n",
    "        x1 = self.conv1(pos, batch)\n",
    "        x2 = self.conv2(x1, batch)\n",
    "        x3 = self.conv3(x2, batch)\n",
    "        out = self.lin1(torch.cat([x1, x2, x3], dim=1))\n",
    "        out = self.mlp(out)\n",
    "        if self.typ == \"Edges\" or self.typ == \"Types\":\n",
    "            return F.log_softmax(out, dim=1)\n",
    "        if self.typ == \"Normals\":\n",
    "            return F.normalize(out, p=2, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualizing the Nearest Neighbour Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "tf_pre = T.Compose([\n",
    "    T.FixedPoints(1000),\n",
    "    T.NormalizeScale(),\n",
    "    T.KNNGraph(k=6)\n",
    "])\n",
    "\n",
    "dataset = ABCDataset(\"data/ml/ABC_graph\", \"Edges\", pre_transform=tf_pre)\n",
    "vd = dataset[0].pos.numpy()\n",
    "p = mp.plot(vd, shading={\"point_size\": 0.15})\n",
    "p.add_edges(vd, dataset[0].edge_index.numpy().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Defining the Loss Function (Normals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class Cosine_Loss(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Cosine_Loss,self).__init__()\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        dotp = torch.mul(x, y).sum(1)\n",
    "        loss = torch.sum(1 - dotp.pow(2)) / x.shape[0]\n",
    "        angle = torch.sum(torch.acos(\n",
    "                torch.clamp(torch.abs(dotp), 0.0, 1.0))) / x.shape[0]\n",
    "        return loss, angle\n",
    "\n",
    "cosine_loss = Cosine_Loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Defining the Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def train(loader, typ=\"Edges\"):\n",
    "    model.train()\n",
    "\n",
    "    for i, data in enumerate(loader):\n",
    "        total_loss = correct_nodes = total_nodes = 0\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        \n",
    "        if typ == \"Edges\" or typ == \"Types\":\n",
    "            loss = F.nll_loss(out, data.y)\n",
    "        if typ == \"Normals\":\n",
    "            loss, angle = cosine_loss(out, data.y)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if typ == \"Edges\" or typ == \"Types\":\n",
    "            pred = out.max(dim=1)[1]\n",
    "            correct_nodes += pred.eq(data.y).sum().item()\n",
    "            total_nodes += data.num_nodes\n",
    "            acc = correct_nodes / total_nodes\n",
    "            \n",
    "        if typ == \"Normals\":\n",
    "            acc = angle.item()*180/np.pi\n",
    "        \n",
    "        print('[Train {}/{}] Loss: {:.4f}, Accuracy: {:.4f}'.format(\n",
    "              i + 1, len(loader), total_loss / loader.batch_size, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Defining the Testing Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def test(loader, typ=\"Edges\"):\n",
    "    model.eval()\n",
    "\n",
    "    correct_nodes = total_nodes = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "            \n",
    "        if typ == \"Edges\" or typ == \"Types\":\n",
    "            pred = out.max(dim=1)[1]\n",
    "            correct_nodes += pred.eq(data.y).sum().item()\n",
    "            total_nodes += data.num_nodes\n",
    "            \n",
    "        if typ == \"Normals\":\n",
    "            _, angle = cosine_loss(out, data.y)\n",
    "            correct_nodes += angle.item() * 180 / np.pi\n",
    "            total_nodes += 1\n",
    "            \n",
    "    return correct_nodes / total_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Running the Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "typ = \"Edges\"\n",
    "\n",
    "if typ == \"Edges\":\n",
    "    train_dataset = train_dataset_e\n",
    "    test_dataset = test_dataset_e\n",
    "\n",
    "if typ == \"Normals\":\n",
    "    train_dataset = train_dataset_n\n",
    "    test_dataset = test_dataset_n\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(train_dataset.num_classes, k=30, typ=typ).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, \n",
    "                                            step_size=20, gamma=0.8)\n",
    "\n",
    "for epoch in range(1, 2):\n",
    "    train(train_loader, typ=typ)\n",
    "    acc = test(test_loader, typ=typ)\n",
    "    print('Test: {:02d}, Accuracy: {:.4f}'.format(epoch, acc))\n",
    "    torch.save(model.state_dict(), \"%02i_%.2f.dat\"%(epoch, acc))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading a Pretrained Model - Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "typ = \"Edges\"\n",
    "test_dataset = test_dataset_e\n",
    "state_file = \"Edges_72_0.96.dat\"\n",
    "\n",
    "model = Net(test_dataset.num_classes, k=30, typ=typ)\n",
    "if torch.cuda.is_available():\n",
    "    state = torch.load(\"data/ml/ABC/models/%s\"%state_file)\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    state = torch.load(\"data/ml/ABC/models/%s\"%state_file, \n",
    "                       map_location=torch.device('cpu'))\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model.load_state_dict(state)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualizing the Predicted Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "loader = iter(test_loader)\n",
    "\n",
    "d = loader.next()\n",
    "with torch.no_grad():\n",
    "    out = model(d.to(device))\n",
    "\n",
    "v = d.pos.cpu().numpy()\n",
    "y = d.y.cpu().numpy()\n",
    "\n",
    "# Calculate accuracy \n",
    "acc = test(test_loader)\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot groundtruth\n",
    "mp.plot(v, c=-y, shading={\"point_size\":0.15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = out.max(dim=1)[1].cpu().numpy()    \n",
    "# Plot estimation\n",
    "mp.plot(v, c=-e, shading={\"point_size\": 0.15})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Pretrained Model - Normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typ = \"Normals\"\n",
    "test_dataset = test_dataset_n\n",
    "state_file = \"Normals_44_12.52.dat\"\n",
    "\n",
    "model = Net(test_dataset.num_classes, k=30, typ=typ)\n",
    "if torch.cuda.is_available():\n",
    "    state = torch.load(\"data/ml/ABC/models/%s\"%state_file)\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    state = torch.load(\"data/ml/ABC/models/%s\"%state_file, \n",
    "                       map_location=torch.device('cpu'))\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model.load_state_dict(state)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Predicted Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "loader = iter(test_loader)\n",
    "\n",
    "d = loader.next()\n",
    "with torch.no_grad():\n",
    "    out = model(d.to(device))\n",
    "\n",
    "v = d.pos.cpu().numpy()\n",
    "y = d.y.cpu().numpy()\n",
    "\n",
    "# Calculate accuracy\n",
    "_, angle = cosine_loss(out, d.y)\n",
    "print(angle.item() * 180 / np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot groundtruth\n",
    "c1 = np.abs(y)\n",
    "mp.plot(v, c=c1, shading={\"point_size\":0.15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = out.cpu().numpy()\n",
    "c2 = np.abs(n)\n",
    "# Plot estimation\n",
    "mp.plot(v, c=c2, shading={\"point_size\": 0.15})    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "rise": {
   "center": false,
   "progress": false,
   "scroll": true,
   "slidenumber": false,
   "theme": "while",
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
